{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8482,"status":"ok","timestamp":1688097889091,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"lmXOrwPD48El","outputId":"9210d121-e584-46b7-9607-fe81c314f452"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n","  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.16)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.6.3)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n","Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n","Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.2.0\n"]}],"source":["!pip install optuna"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26695,"status":"ok","timestamp":1688097915767,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"0P6a7wTK6ZKe","outputId":"e203354a-b50f-4c5d-e719-c8c96b527fe1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","from pathlib import Path\n","from glob import glob\n","\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split as TTS\n","\n","import lightgbm as lgb\n","from sklearn.multioutput import MultiOutputRegressor as mor\n","from sklearn.metrics import mean_squared_error as MAE\n","from sklearn.model_selection import KFold\n","\n","import optuna\n","\n","path_start = Path(\"/content/drive/MyDrive/Nishika/Mansion_2023_spring\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19478,"status":"ok","timestamp":1688097935239,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"Z2RtcX9Q_X4Y","outputId":"21c03690-7eed-474d-c889-e5e3623b9673"},"outputs":[{"output_type":"stream","name":"stdout","text":["(784713, 28)\n"]}],"source":["train = pd.read_csv(path_start/\"input/df_train.csv\", index_col=0)\n","test = pd.read_csv(path_start/\"input/test.csv\", index_col=0)\n","sample = pd.read_csv(path_start/\"input/sample_submission.csv\")\n","\n","df_ConCat = pd.concat([train, test])\n","print(df_ConCat.shape)"]},{"cell_type":"markdown","metadata":{"id":"7sxlvYQjNRtc"},"source":["## 特徴量の削除"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":372},"executionInfo":{"elapsed":4563,"status":"ok","timestamp":1688097939765,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"OFOiBBngVQEO","outputId":"506818f4-5ea7-4a77-d1c5-352ccabeb2fa"},"outputs":[{"output_type":"display_data","data":{"text/plain":["(784713, 12)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["        ID  市区町村コード 都道府県名    地区名  最寄駅：距離（分）  面積（㎡） 今後の利用目的          都市計画  \\\n","0  8067540     8217   茨城県    野々井         13     70     NaN       第１種住居地域   \n","1  8027265     8219   茨城県  ひたち野東          8     70      住宅  第２種中高層住居専用地域   \n","2  8061526     8220   茨城県     苅間          4    105     NaN          商業地域   \n","3  8086147     8220   茨城県     並木         75    100     NaN  第１種中高層住居専用地域   \n","4  8049498     8224   茨城県   ひがし野          8     95      住宅        近隣商業地域   \n","\n","   建ぺい率（％）  容積率（％）   改装  取引価格（総額）_log  \n","0     60.0   200.0  未改装      6.977724  \n","1     60.0   200.0  未改装      7.255273  \n","2     80.0   400.0  未改装      7.556303  \n","3     60.0   200.0  未改装      7.380211  \n","4     80.0   200.0  未改装      7.518514  "],"text/html":["\n","  <div id=\"df-39f29dee-ff57-4812-adf9-f3aa6a4178af\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>市区町村コード</th>\n","      <th>都道府県名</th>\n","      <th>地区名</th>\n","      <th>最寄駅：距離（分）</th>\n","      <th>面積（㎡）</th>\n","      <th>今後の利用目的</th>\n","      <th>都市計画</th>\n","      <th>建ぺい率（％）</th>\n","      <th>容積率（％）</th>\n","      <th>改装</th>\n","      <th>取引価格（総額）_log</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8067540</td>\n","      <td>8217</td>\n","      <td>茨城県</td>\n","      <td>野々井</td>\n","      <td>13</td>\n","      <td>70</td>\n","      <td>NaN</td>\n","      <td>第１種住居地域</td>\n","      <td>60.0</td>\n","      <td>200.0</td>\n","      <td>未改装</td>\n","      <td>6.977724</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8027265</td>\n","      <td>8219</td>\n","      <td>茨城県</td>\n","      <td>ひたち野東</td>\n","      <td>8</td>\n","      <td>70</td>\n","      <td>住宅</td>\n","      <td>第２種中高層住居専用地域</td>\n","      <td>60.0</td>\n","      <td>200.0</td>\n","      <td>未改装</td>\n","      <td>7.255273</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8061526</td>\n","      <td>8220</td>\n","      <td>茨城県</td>\n","      <td>苅間</td>\n","      <td>4</td>\n","      <td>105</td>\n","      <td>NaN</td>\n","      <td>商業地域</td>\n","      <td>80.0</td>\n","      <td>400.0</td>\n","      <td>未改装</td>\n","      <td>7.556303</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8086147</td>\n","      <td>8220</td>\n","      <td>茨城県</td>\n","      <td>並木</td>\n","      <td>75</td>\n","      <td>100</td>\n","      <td>NaN</td>\n","      <td>第１種中高層住居専用地域</td>\n","      <td>60.0</td>\n","      <td>200.0</td>\n","      <td>未改装</td>\n","      <td>7.380211</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8049498</td>\n","      <td>8224</td>\n","      <td>茨城県</td>\n","      <td>ひがし野</td>\n","      <td>8</td>\n","      <td>95</td>\n","      <td>住宅</td>\n","      <td>近隣商業地域</td>\n","      <td>80.0</td>\n","      <td>200.0</td>\n","      <td>未改装</td>\n","      <td>7.518514</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39f29dee-ff57-4812-adf9-f3aa6a4178af')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-39f29dee-ff57-4812-adf9-f3aa6a4178af button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-39f29dee-ff57-4812-adf9-f3aa6a4178af');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["Fvalue = lambda x: df_ConCat.drop(x, axis=1)\n","List_del = [\"取引時点\", \"市区町村名\", \"間取り\", \"種類\",\n","            \"前面道路：方位\", \"前面道路：種類\",\t\"前面道路：幅員（ｍ）\", \"地域\", \"土地の形状\",\n","            \"間口\", \"建物の構造\", \"延床面積（㎡）\", \"用途\", \"取引の事情等\",\n","            \"最寄駅：名称\", \"建築年\"]\n","\n","for c in List_del:\n","  df_ConCat = df_ConCat.drop(c, axis=1)\n","display(df_ConCat.shape)\n","df_ConCat.head()"]},{"cell_type":"markdown","metadata":{"id":"ag5G_aZT0HkL"},"source":["## 標準化"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"elapsed":955,"status":"ok","timestamp":1688097940708,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"xGQ8gv6i0NW6","outputId":"ee4ff095-6fdf-41be-f078-4f9ac278058c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        ID  市区町村コード 都道府県名    地区名  最寄駅：距離（分）     面積（㎡） 今後の利用目的          都市計画  \\\n","0  8067540     8217   茨城県    野々井   0.144049  0.431679     NaN       第１種住居地域   \n","1  8027265     8219   茨城県  ひたち野東  -0.266625  0.431679      住宅  第２種中高層住居専用地域   \n","2  8061526     8220   茨城県     苅間  -0.595164  1.726269     NaN          商業地域   \n","3  8086147     8220   茨城県     並木   5.236408  1.541328     NaN  第１種中高層住居専用地域   \n","4  8049498     8224   茨城県   ひがし野  -0.266625  1.356387      住宅        近隣商業地域   \n","\n","    建ぺい率（％）    容積率（％）   改装  取引価格（総額）_log  \n","0 -0.741730 -0.695601  未改装      6.977724  \n","1 -0.741730 -0.695601  未改装      7.255273  \n","2  1.177623  0.650409  未改装      7.556303  \n","3 -0.741730 -0.695601  未改装      7.380211  \n","4  1.177623 -0.695601  未改装      7.518514  "],"text/html":["\n","  <div id=\"df-5eb61420-4861-4ecd-8fd3-d0be7e7a68a0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>市区町村コード</th>\n","      <th>都道府県名</th>\n","      <th>地区名</th>\n","      <th>最寄駅：距離（分）</th>\n","      <th>面積（㎡）</th>\n","      <th>今後の利用目的</th>\n","      <th>都市計画</th>\n","      <th>建ぺい率（％）</th>\n","      <th>容積率（％）</th>\n","      <th>改装</th>\n","      <th>取引価格（総額）_log</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8067540</td>\n","      <td>8217</td>\n","      <td>茨城県</td>\n","      <td>野々井</td>\n","      <td>0.144049</td>\n","      <td>0.431679</td>\n","      <td>NaN</td>\n","      <td>第１種住居地域</td>\n","      <td>-0.741730</td>\n","      <td>-0.695601</td>\n","      <td>未改装</td>\n","      <td>6.977724</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8027265</td>\n","      <td>8219</td>\n","      <td>茨城県</td>\n","      <td>ひたち野東</td>\n","      <td>-0.266625</td>\n","      <td>0.431679</td>\n","      <td>住宅</td>\n","      <td>第２種中高層住居専用地域</td>\n","      <td>-0.741730</td>\n","      <td>-0.695601</td>\n","      <td>未改装</td>\n","      <td>7.255273</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8061526</td>\n","      <td>8220</td>\n","      <td>茨城県</td>\n","      <td>苅間</td>\n","      <td>-0.595164</td>\n","      <td>1.726269</td>\n","      <td>NaN</td>\n","      <td>商業地域</td>\n","      <td>1.177623</td>\n","      <td>0.650409</td>\n","      <td>未改装</td>\n","      <td>7.556303</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8086147</td>\n","      <td>8220</td>\n","      <td>茨城県</td>\n","      <td>並木</td>\n","      <td>5.236408</td>\n","      <td>1.541328</td>\n","      <td>NaN</td>\n","      <td>第１種中高層住居専用地域</td>\n","      <td>-0.741730</td>\n","      <td>-0.695601</td>\n","      <td>未改装</td>\n","      <td>7.380211</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8049498</td>\n","      <td>8224</td>\n","      <td>茨城県</td>\n","      <td>ひがし野</td>\n","      <td>-0.266625</td>\n","      <td>1.356387</td>\n","      <td>住宅</td>\n","      <td>近隣商業地域</td>\n","      <td>1.177623</td>\n","      <td>-0.695601</td>\n","      <td>未改装</td>\n","      <td>7.518514</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5eb61420-4861-4ecd-8fd3-d0be7e7a68a0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5eb61420-4861-4ecd-8fd3-d0be7e7a68a0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5eb61420-4861-4ecd-8fd3-d0be7e7a68a0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["List_std = [\"最寄駅：距離（分）\", \"面積（㎡）\", \"建ぺい率（％）\", \"容積率（％）\"]\n","scaler = StandardScaler()\n","scaler.fit(df_ConCat[List_std])\n","df_ConCat[List_std] = scaler.transform(df_ConCat[List_std])\n","df_ConCat.head()"]},{"cell_type":"markdown","metadata":{"id":"qEY0Sr_INeAo"},"source":["## 特徴量追加"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202139,"status":"ok","timestamp":1688098142836,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"Km3A7hlVNgxq","outputId":"b2e9143e-8279-4c9b-f2a4-4634e337e87f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(784713, 374)"]},"metadata":{},"execution_count":6}],"source":["for i in glob(str(path_start/\"LoE/*.csv\")):\n","  df_ConCat = pd.merge(df_ConCat, pd.read_csv(i), on=\"ID\", how=\"left\")\n","\n","for i in glob(str(path_start/\"TargetEncoding/*.csv\")):\n","  df_ConCat = pd.merge(df_ConCat, pd.read_csv(i), on=\"ID\", how=\"left\")\n","\n","for i in glob(str(path_start/\"feature_value/*.csv\")):\n","  df_ConCat = pd.merge(df_ConCat, pd.read_csv(i), on=\"ID\", how=\"left\")\n","df_ConCat.shape"]},{"cell_type":"markdown","metadata":{"id":"D00Rx-p06wjZ"},"source":["## 特徴量を150個に絞る"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":885},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1688098142838,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"8zeLwKgk7Ibx","outputId":"665f87c0-5e31-4f4d-faef-de0744cb274f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["49"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["['地区名',\n"," '建築年',\n"," '面積（㎡）',\n"," '都道府県名',\n"," '市区町村名_TE面積（㎡）',\n"," '最寄駅：距離（分）',\n"," '市区町村コード',\n"," '改装',\n"," '取引時点_TE取引時期_年四半期',\n"," '市区町村名_TE最寄駅：距離（分）',\n"," '間取り_TE取引時期_四半期',\n"," '市区町村名_TE取引時期_四半期',\n"," '取引時点_TE取引時期_年',\n"," '市区町村名_TE容積率（％）',\n"," '取引時点_TE建築年',\n"," '最寄駅：名称_TE容積率（％）',\n"," '地区名_TE最寄駅：距離（分）',\n"," '市区町村名_TE取引時期_年',\n"," '市区町村名_TE取引時期_年四半期',\n"," '市区町村名_TE取引-建築',\n"," '今後の利用目的',\n"," '取引の事情等_TE取引時期_四半期',\n"," '都市計画',\n"," '取引時点_TE面積（㎡）',\n"," '都道府県名_TE面積（㎡）',\n"," '市区町村名_TE建築年',\n"," '容積率（％）',\n"," '取引時点_TE取引-建築',\n"," '最寄駅：名称_TE建ぺい率（％）',\n"," '取引時点_TE最寄駅：距離（分）',\n"," '取引の事情等_TE建築年',\n"," '最寄駅：名称_TE取引時期_四半期',\n"," '市区町村名_TE建ぺい率（％）',\n"," '取引時点_TE建ぺい率（％）',\n"," '地区名_TE建築年',\n"," '取引の事情等_TE容積率（％）',\n"," '最寄駅：名称_TE取引-建築',\n"," '建物の構造_TE最寄駅：距離（分）',\n"," '都市計画_TE最寄駅：距離（分）',\n"," '間取り_TE取引時期_年',\n"," '最寄駅：名称_TE最寄駅：距離（分）',\n"," '取引の事情等_TE取引時期_年',\n"," '地区名_TE容積率（％）',\n"," '最寄駅：名称_TE取引時期_年四半期',\n"," '取引時点_TE容積率（％）',\n"," '地区名_TE取引-建築',\n"," '最寄駅：名称_TE面積（㎡）',\n"," '取引の事情等_TE面積（㎡）',\n"," '今後の利用目的_TE面積（㎡）']"]},"metadata":{}}],"source":["list_handred = pd.read_csv(path_start/\"my_list_50.csv\", header=None).values.tolist()\n","flattened = [x for row in list_handred for x in row]\n","flattened.remove(\"ID\")\n","display(len(flattened))\n","display(flattened)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":543},"executionInfo":{"elapsed":4390,"status":"ok","timestamp":1688098147194,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"NzkO6Osk-szh","outputId":"eedab708-fe2f-4a4f-e521-af0ee9ff64a6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        ID  取引価格（総額）_log    地区名     建築年     面積（㎡） 都道府県名  市区町村名_TE面積（㎡）  \\\n","0  8067540      6.977724    野々井  1996.0  0.431679   茨城県       0.201441   \n","1  8027265      7.255273  ひたち野東  1998.0  0.431679   茨城県       0.506946   \n","2  8061526      7.556303     苅間  2009.0  1.726269   茨城県       1.006775   \n","3  8086147      7.380211     並木  2007.0  1.541328   茨城県       1.006775   \n","4  8049498      7.518514   ひがし野  2009.0  1.356387   茨城県       0.690122   \n","\n","   最寄駅：距離（分）  市区町村コード   改装  ...  間取り_TE取引時期_年  最寄駅：名称_TE最寄駅：距離（分）  \\\n","0   0.144049     8217  未改装  ...     -0.042201           -0.051169   \n","1  -0.266625     8219  未改装  ...     -0.042201           -0.519268   \n","2  -0.595164     8220  未改装  ...     -0.042201           -0.587841   \n","3   5.236408     8220  未改装  ...     -0.103538            1.064501   \n","4  -0.266625     8224  未改装  ...     -0.103538           -0.262707   \n","\n","   取引の事情等_TE取引時期_年  地区名_TE容積率（％）  最寄駅：名称_TE取引時期_年四半期  取引時点_TE容積率（％）  \\\n","0          0.01425     -0.433236           -0.096591      -0.102286   \n","1          0.01425      0.203528            0.046625       0.028981   \n","2          0.01425      0.306295            0.463295      -0.036798   \n","3          0.01425     -0.416577           -0.048201      -0.043977   \n","4          0.01425     -0.690946            0.420120       0.019880   \n","\n","   地区名_TE取引-建築  最寄駅：名称_TE面積（㎡）  取引の事情等_TE面積（㎡）  今後の利用目的_TE面積（㎡）  \n","0     0.026846        0.105338       -0.002202         0.025406  \n","1    -0.704945        0.641592       -0.002202         0.008770  \n","2    -0.888053        1.280655       -0.002202         0.025406  \n","3     0.196723        0.967881       -0.002202         0.025406  \n","4    -0.926995        0.736961       -0.002202         0.008770  \n","\n","[5 rows x 51 columns]"],"text/html":["\n","  <div id=\"df-b9e85033-d48c-42c4-8696-0bb6ce17bf47\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>取引価格（総額）_log</th>\n","      <th>地区名</th>\n","      <th>建築年</th>\n","      <th>面積（㎡）</th>\n","      <th>都道府県名</th>\n","      <th>市区町村名_TE面積（㎡）</th>\n","      <th>最寄駅：距離（分）</th>\n","      <th>市区町村コード</th>\n","      <th>改装</th>\n","      <th>...</th>\n","      <th>間取り_TE取引時期_年</th>\n","      <th>最寄駅：名称_TE最寄駅：距離（分）</th>\n","      <th>取引の事情等_TE取引時期_年</th>\n","      <th>地区名_TE容積率（％）</th>\n","      <th>最寄駅：名称_TE取引時期_年四半期</th>\n","      <th>取引時点_TE容積率（％）</th>\n","      <th>地区名_TE取引-建築</th>\n","      <th>最寄駅：名称_TE面積（㎡）</th>\n","      <th>取引の事情等_TE面積（㎡）</th>\n","      <th>今後の利用目的_TE面積（㎡）</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8067540</td>\n","      <td>6.977724</td>\n","      <td>野々井</td>\n","      <td>1996.0</td>\n","      <td>0.431679</td>\n","      <td>茨城県</td>\n","      <td>0.201441</td>\n","      <td>0.144049</td>\n","      <td>8217</td>\n","      <td>未改装</td>\n","      <td>...</td>\n","      <td>-0.042201</td>\n","      <td>-0.051169</td>\n","      <td>0.01425</td>\n","      <td>-0.433236</td>\n","      <td>-0.096591</td>\n","      <td>-0.102286</td>\n","      <td>0.026846</td>\n","      <td>0.105338</td>\n","      <td>-0.002202</td>\n","      <td>0.025406</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8027265</td>\n","      <td>7.255273</td>\n","      <td>ひたち野東</td>\n","      <td>1998.0</td>\n","      <td>0.431679</td>\n","      <td>茨城県</td>\n","      <td>0.506946</td>\n","      <td>-0.266625</td>\n","      <td>8219</td>\n","      <td>未改装</td>\n","      <td>...</td>\n","      <td>-0.042201</td>\n","      <td>-0.519268</td>\n","      <td>0.01425</td>\n","      <td>0.203528</td>\n","      <td>0.046625</td>\n","      <td>0.028981</td>\n","      <td>-0.704945</td>\n","      <td>0.641592</td>\n","      <td>-0.002202</td>\n","      <td>0.008770</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8061526</td>\n","      <td>7.556303</td>\n","      <td>苅間</td>\n","      <td>2009.0</td>\n","      <td>1.726269</td>\n","      <td>茨城県</td>\n","      <td>1.006775</td>\n","      <td>-0.595164</td>\n","      <td>8220</td>\n","      <td>未改装</td>\n","      <td>...</td>\n","      <td>-0.042201</td>\n","      <td>-0.587841</td>\n","      <td>0.01425</td>\n","      <td>0.306295</td>\n","      <td>0.463295</td>\n","      <td>-0.036798</td>\n","      <td>-0.888053</td>\n","      <td>1.280655</td>\n","      <td>-0.002202</td>\n","      <td>0.025406</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8086147</td>\n","      <td>7.380211</td>\n","      <td>並木</td>\n","      <td>2007.0</td>\n","      <td>1.541328</td>\n","      <td>茨城県</td>\n","      <td>1.006775</td>\n","      <td>5.236408</td>\n","      <td>8220</td>\n","      <td>未改装</td>\n","      <td>...</td>\n","      <td>-0.103538</td>\n","      <td>1.064501</td>\n","      <td>0.01425</td>\n","      <td>-0.416577</td>\n","      <td>-0.048201</td>\n","      <td>-0.043977</td>\n","      <td>0.196723</td>\n","      <td>0.967881</td>\n","      <td>-0.002202</td>\n","      <td>0.025406</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8049498</td>\n","      <td>7.518514</td>\n","      <td>ひがし野</td>\n","      <td>2009.0</td>\n","      <td>1.356387</td>\n","      <td>茨城県</td>\n","      <td>0.690122</td>\n","      <td>-0.266625</td>\n","      <td>8224</td>\n","      <td>未改装</td>\n","      <td>...</td>\n","      <td>-0.103538</td>\n","      <td>-0.262707</td>\n","      <td>0.01425</td>\n","      <td>-0.690946</td>\n","      <td>0.420120</td>\n","      <td>0.019880</td>\n","      <td>-0.926995</td>\n","      <td>0.736961</td>\n","      <td>-0.002202</td>\n","      <td>0.008770</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 51 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9e85033-d48c-42c4-8696-0bb6ce17bf47')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b9e85033-d48c-42c4-8696-0bb6ce17bf47 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b9e85033-d48c-42c4-8696-0bb6ce17bf47');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}],"source":["df_ConCat2 = pd.concat([df_ConCat[[\"ID\", \"取引価格（総額）_log\"]], df_ConCat[flattened]], axis=1)\n","df_ConCat2.head()"]},{"cell_type":"markdown","metadata":{"id":"IC17fi0IBZV_"},"source":["## ラベルエンコーディング"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1688098147196,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"mbZPgeX3BRrc","outputId":"5b93bb0e-ee58-4da0-f341-9f5ddb013a97"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['地区名', '都道府県名', '改装', '今後の利用目的', '都市計画']"]},"metadata":{},"execution_count":9}],"source":["List_Encode = []\n","for i, t in enumerate(df_ConCat2.dtypes):\n","  if t!=\"float64\" and t!=\"int64\":\n","    List_Encode.append(df_ConCat2.columns[i])\n","\n","List_Encode"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1133,"status":"ok","timestamp":1688098148318,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"mOwQ52vMEmvs"},"outputs":[],"source":["for c in List_Encode:\n","  le = LabelEncoder()\n","  le.fit(df_ConCat2[c])\n","  df_ConCat2[c] = le.transform(df_ConCat2[c])"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1688098148321,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"PIuQaIHZAwsU","outputId":"a5b45eeb-28b8-4bc3-e54e-debcb3de6129"},"outputs":[{"output_type":"display_data","data":{"text/plain":["list"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["['ID', '市区町村コード']"]},"metadata":{}}],"source":["List_plus = [\"用途_住宅\", \"用途_不明\", \"用途_店舗\",\t\"用途_その他\", \"用途_事務所\",\n","             \"用途_駐車場\", \"用途_倉庫\", \"用途_作業場\", \"用途_工場\", \"建物の構造_ＲＣ\",\n","             \"建物の構造_鉄骨造\", \"建物の構造_ＳＲＣ\", \"建物の構造_不明\", \"建物の構造_木造\", \"建物の構造_軽量鉄骨造\",\n","             \"建物の構造_ブロック造\", \"間取り_数字\", \"利用変異\", \"取引の事情等_不明\",\t\"取引の事情等_調停・競売等\",\n","             \"取引の事情等_瑕疵有りの可能性\",\t\"取引の事情等_関係者間取引\", \"取引の事情等_その他事情有り\", \"取引の事情等_他の権利・負担付き\",\n","             \"利用一致_不明\", \"利用一致_住宅\", \"利用一致_その他\", \"利用一致_事務所\", \"利用一致_店舗\",\n","             \"市区町村コード\", \"ID\"]\n","list_and = list(set(list(df_ConCat2.columns)).intersection(set(List_plus)))\n","display(type(list_and))\n","display(list_and)"]},{"cell_type":"markdown","metadata":{"id":"mB-n9c0ETxrJ"},"source":["## 分割"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":495,"status":"ok","timestamp":1688098148801,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"JP0Sq6Pf9tZv"},"outputs":[],"source":["if df_ConCat2[\"取引価格（総額）_log\"].isna().sum()!=0:\n","  test = df_ConCat2[df_ConCat2[\"取引価格（総額）_log\"].isna()==True]\n","  train = df_ConCat2[df_ConCat2[\"取引価格（総額）_log\"].isna()!=True]\n","else:\n","  test = df_ConCat2[df_ConCat2[\"取引価格（総額）_log\"]==0]\n","  train = df_ConCat2[df_ConCat2[\"取引価格（総額）_log\"]!=0]"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1688098148803,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"XCH0oG5OMuZe","outputId":"210b53b7-7de1-4a2a-c0db-816a5c3be308"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        ID    地区名     建築年     面積（㎡）  都道府県名  市区町村名_TE面積（㎡）  最寄駅：距離（分）  市区町村コード  \\\n","0  8067540  11184  1996.0  0.431679     38       0.201441   0.144049     8217   \n","1  8027265     80  1998.0  0.431679     38       0.506946  -0.266625     8219   \n","2  8061526   9896  2009.0  1.726269     38       1.006775  -0.595164     8220   \n","3  8086147    822  2007.0  1.541328     38       1.006775   5.236408     8220   \n","4  8049498     79  2009.0  1.356387     38       0.690122  -0.266625     8224   \n","\n","   改装  取引時点_TE取引時期_年四半期  ...  間取り_TE取引時期_年  最寄駅：名称_TE最寄駅：距離（分）  \\\n","0   1         -1.580274  ...     -0.042201           -0.051169   \n","1   1          0.784888  ...     -0.042201           -0.519268   \n","2   1         -0.666462  ...     -0.042201           -0.587841   \n","3   1         -0.397693  ...     -0.103538            1.064501   \n","4   1          0.731134  ...     -0.103538           -0.262707   \n","\n","   取引の事情等_TE取引時期_年  地区名_TE容積率（％）  最寄駅：名称_TE取引時期_年四半期  取引時点_TE容積率（％）  \\\n","0          0.01425     -0.433236           -0.096591      -0.102286   \n","1          0.01425      0.203528            0.046625       0.028981   \n","2          0.01425      0.306295            0.463295      -0.036798   \n","3          0.01425     -0.416577           -0.048201      -0.043977   \n","4          0.01425     -0.690946            0.420120       0.019880   \n","\n","   地区名_TE取引-建築  最寄駅：名称_TE面積（㎡）  取引の事情等_TE面積（㎡）  今後の利用目的_TE面積（㎡）  \n","0     0.026846        0.105338       -0.002202         0.025406  \n","1    -0.704945        0.641592       -0.002202         0.008770  \n","2    -0.888053        1.280655       -0.002202         0.025406  \n","3     0.196723        0.967881       -0.002202         0.025406  \n","4    -0.926995        0.736961       -0.002202         0.008770  \n","\n","[5 rows x 50 columns]"],"text/html":["\n","  <div id=\"df-c7414b96-76cc-4cda-85be-015dec32a9b5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>地区名</th>\n","      <th>建築年</th>\n","      <th>面積（㎡）</th>\n","      <th>都道府県名</th>\n","      <th>市区町村名_TE面積（㎡）</th>\n","      <th>最寄駅：距離（分）</th>\n","      <th>市区町村コード</th>\n","      <th>改装</th>\n","      <th>取引時点_TE取引時期_年四半期</th>\n","      <th>...</th>\n","      <th>間取り_TE取引時期_年</th>\n","      <th>最寄駅：名称_TE最寄駅：距離（分）</th>\n","      <th>取引の事情等_TE取引時期_年</th>\n","      <th>地区名_TE容積率（％）</th>\n","      <th>最寄駅：名称_TE取引時期_年四半期</th>\n","      <th>取引時点_TE容積率（％）</th>\n","      <th>地区名_TE取引-建築</th>\n","      <th>最寄駅：名称_TE面積（㎡）</th>\n","      <th>取引の事情等_TE面積（㎡）</th>\n","      <th>今後の利用目的_TE面積（㎡）</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8067540</td>\n","      <td>11184</td>\n","      <td>1996.0</td>\n","      <td>0.431679</td>\n","      <td>38</td>\n","      <td>0.201441</td>\n","      <td>0.144049</td>\n","      <td>8217</td>\n","      <td>1</td>\n","      <td>-1.580274</td>\n","      <td>...</td>\n","      <td>-0.042201</td>\n","      <td>-0.051169</td>\n","      <td>0.01425</td>\n","      <td>-0.433236</td>\n","      <td>-0.096591</td>\n","      <td>-0.102286</td>\n","      <td>0.026846</td>\n","      <td>0.105338</td>\n","      <td>-0.002202</td>\n","      <td>0.025406</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8027265</td>\n","      <td>80</td>\n","      <td>1998.0</td>\n","      <td>0.431679</td>\n","      <td>38</td>\n","      <td>0.506946</td>\n","      <td>-0.266625</td>\n","      <td>8219</td>\n","      <td>1</td>\n","      <td>0.784888</td>\n","      <td>...</td>\n","      <td>-0.042201</td>\n","      <td>-0.519268</td>\n","      <td>0.01425</td>\n","      <td>0.203528</td>\n","      <td>0.046625</td>\n","      <td>0.028981</td>\n","      <td>-0.704945</td>\n","      <td>0.641592</td>\n","      <td>-0.002202</td>\n","      <td>0.008770</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8061526</td>\n","      <td>9896</td>\n","      <td>2009.0</td>\n","      <td>1.726269</td>\n","      <td>38</td>\n","      <td>1.006775</td>\n","      <td>-0.595164</td>\n","      <td>8220</td>\n","      <td>1</td>\n","      <td>-0.666462</td>\n","      <td>...</td>\n","      <td>-0.042201</td>\n","      <td>-0.587841</td>\n","      <td>0.01425</td>\n","      <td>0.306295</td>\n","      <td>0.463295</td>\n","      <td>-0.036798</td>\n","      <td>-0.888053</td>\n","      <td>1.280655</td>\n","      <td>-0.002202</td>\n","      <td>0.025406</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8086147</td>\n","      <td>822</td>\n","      <td>2007.0</td>\n","      <td>1.541328</td>\n","      <td>38</td>\n","      <td>1.006775</td>\n","      <td>5.236408</td>\n","      <td>8220</td>\n","      <td>1</td>\n","      <td>-0.397693</td>\n","      <td>...</td>\n","      <td>-0.103538</td>\n","      <td>1.064501</td>\n","      <td>0.01425</td>\n","      <td>-0.416577</td>\n","      <td>-0.048201</td>\n","      <td>-0.043977</td>\n","      <td>0.196723</td>\n","      <td>0.967881</td>\n","      <td>-0.002202</td>\n","      <td>0.025406</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8049498</td>\n","      <td>79</td>\n","      <td>2009.0</td>\n","      <td>1.356387</td>\n","      <td>38</td>\n","      <td>0.690122</td>\n","      <td>-0.266625</td>\n","      <td>8224</td>\n","      <td>1</td>\n","      <td>0.731134</td>\n","      <td>...</td>\n","      <td>-0.103538</td>\n","      <td>-0.262707</td>\n","      <td>0.01425</td>\n","      <td>-0.690946</td>\n","      <td>0.420120</td>\n","      <td>0.019880</td>\n","      <td>-0.926995</td>\n","      <td>0.736961</td>\n","      <td>-0.002202</td>\n","      <td>0.008770</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 50 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7414b96-76cc-4cda-85be-015dec32a9b5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c7414b96-76cc-4cda-85be-015dec32a9b5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c7414b96-76cc-4cda-85be-015dec32a9b5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}],"source":["aim = \"取引価格（総額）_log\"\n","df_y = train[aim]\n","df_x = train.drop([aim], axis=1)\n","test = test.drop([aim], axis=1)\n","df_x.head()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1688098148805,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"v-7fRwmtOlLS","outputId":"af56205a-4d29-429e-d3f8-25320eff3095"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["             ID   地区名     建築年     面積（㎡）  都道府県名  市区町村名_TE面積（㎡）  最寄駅：距離（分）  \\\n","765412  1000077  4280  2016.0  0.616621      4       0.365548  -0.841569   \n","765413  1000081  4280  2012.0  0.616621      4       0.365548  -0.677299   \n","765414  1000128  4280  1984.0  0.061796      4       0.365548  -0.759434   \n","765415  1000129  4280  1986.0 -1.232794      4       0.365548  -0.759434   \n","765416  1000130  4280  2016.0  0.616621      4       0.365548  -0.841569   \n","\n","        市区町村コード  改装  取引時点_TE取引時期_年四半期  ...  間取り_TE取引時期_年  最寄駅：名称_TE最寄駅：距離（分）  \\\n","765412     1101   1          1.591193  ...     -0.042201            0.286794   \n","765413     1101   1          1.591193  ...      0.055225            0.286794   \n","765414     1101   1          1.644947  ...      0.055225            0.017191   \n","765415     1101   1          1.644947  ...     -0.054852            0.017191   \n","765416     1101   1          1.644947  ...     -0.042201            0.017191   \n","\n","        取引の事情等_TE取引時期_年  地区名_TE容積率（％）  最寄駅：名称_TE取引時期_年四半期  取引時点_TE容積率（％）  \\\n","765412          0.01425       0.59565           -0.110204       0.089514   \n","765413          0.01425       0.59565           -0.110204       0.089514   \n","765414          0.01425       0.59565           -0.063107       0.114934   \n","765415          0.01425       0.59565           -0.063107       0.114934   \n","765416          0.01425       0.59565           -0.063107       0.114934   \n","\n","        地区名_TE取引-建築  最寄駅：名称_TE面積（㎡）  取引の事情等_TE面積（㎡）  今後の利用目的_TE面積（㎡）  \n","765412     0.474869        0.236322       -0.002202        -0.565428  \n","765413     0.474869        0.236322       -0.002202         0.008770  \n","765414     0.474869        0.325373       -0.002202         0.008770  \n","765415     0.474869        0.325373       -0.002202         0.008770  \n","765416     0.474869        0.325373       -0.002202         0.008770  \n","\n","[5 rows x 50 columns]"],"text/html":["\n","  <div id=\"df-f63f27a6-9b4b-4e0f-9cd3-a20b8b6c60e7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>地区名</th>\n","      <th>建築年</th>\n","      <th>面積（㎡）</th>\n","      <th>都道府県名</th>\n","      <th>市区町村名_TE面積（㎡）</th>\n","      <th>最寄駅：距離（分）</th>\n","      <th>市区町村コード</th>\n","      <th>改装</th>\n","      <th>取引時点_TE取引時期_年四半期</th>\n","      <th>...</th>\n","      <th>間取り_TE取引時期_年</th>\n","      <th>最寄駅：名称_TE最寄駅：距離（分）</th>\n","      <th>取引の事情等_TE取引時期_年</th>\n","      <th>地区名_TE容積率（％）</th>\n","      <th>最寄駅：名称_TE取引時期_年四半期</th>\n","      <th>取引時点_TE容積率（％）</th>\n","      <th>地区名_TE取引-建築</th>\n","      <th>最寄駅：名称_TE面積（㎡）</th>\n","      <th>取引の事情等_TE面積（㎡）</th>\n","      <th>今後の利用目的_TE面積（㎡）</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>765412</th>\n","      <td>1000077</td>\n","      <td>4280</td>\n","      <td>2016.0</td>\n","      <td>0.616621</td>\n","      <td>4</td>\n","      <td>0.365548</td>\n","      <td>-0.841569</td>\n","      <td>1101</td>\n","      <td>1</td>\n","      <td>1.591193</td>\n","      <td>...</td>\n","      <td>-0.042201</td>\n","      <td>0.286794</td>\n","      <td>0.01425</td>\n","      <td>0.59565</td>\n","      <td>-0.110204</td>\n","      <td>0.089514</td>\n","      <td>0.474869</td>\n","      <td>0.236322</td>\n","      <td>-0.002202</td>\n","      <td>-0.565428</td>\n","    </tr>\n","    <tr>\n","      <th>765413</th>\n","      <td>1000081</td>\n","      <td>4280</td>\n","      <td>2012.0</td>\n","      <td>0.616621</td>\n","      <td>4</td>\n","      <td>0.365548</td>\n","      <td>-0.677299</td>\n","      <td>1101</td>\n","      <td>1</td>\n","      <td>1.591193</td>\n","      <td>...</td>\n","      <td>0.055225</td>\n","      <td>0.286794</td>\n","      <td>0.01425</td>\n","      <td>0.59565</td>\n","      <td>-0.110204</td>\n","      <td>0.089514</td>\n","      <td>0.474869</td>\n","      <td>0.236322</td>\n","      <td>-0.002202</td>\n","      <td>0.008770</td>\n","    </tr>\n","    <tr>\n","      <th>765414</th>\n","      <td>1000128</td>\n","      <td>4280</td>\n","      <td>1984.0</td>\n","      <td>0.061796</td>\n","      <td>4</td>\n","      <td>0.365548</td>\n","      <td>-0.759434</td>\n","      <td>1101</td>\n","      <td>1</td>\n","      <td>1.644947</td>\n","      <td>...</td>\n","      <td>0.055225</td>\n","      <td>0.017191</td>\n","      <td>0.01425</td>\n","      <td>0.59565</td>\n","      <td>-0.063107</td>\n","      <td>0.114934</td>\n","      <td>0.474869</td>\n","      <td>0.325373</td>\n","      <td>-0.002202</td>\n","      <td>0.008770</td>\n","    </tr>\n","    <tr>\n","      <th>765415</th>\n","      <td>1000129</td>\n","      <td>4280</td>\n","      <td>1986.0</td>\n","      <td>-1.232794</td>\n","      <td>4</td>\n","      <td>0.365548</td>\n","      <td>-0.759434</td>\n","      <td>1101</td>\n","      <td>1</td>\n","      <td>1.644947</td>\n","      <td>...</td>\n","      <td>-0.054852</td>\n","      <td>0.017191</td>\n","      <td>0.01425</td>\n","      <td>0.59565</td>\n","      <td>-0.063107</td>\n","      <td>0.114934</td>\n","      <td>0.474869</td>\n","      <td>0.325373</td>\n","      <td>-0.002202</td>\n","      <td>0.008770</td>\n","    </tr>\n","    <tr>\n","      <th>765416</th>\n","      <td>1000130</td>\n","      <td>4280</td>\n","      <td>2016.0</td>\n","      <td>0.616621</td>\n","      <td>4</td>\n","      <td>0.365548</td>\n","      <td>-0.841569</td>\n","      <td>1101</td>\n","      <td>1</td>\n","      <td>1.644947</td>\n","      <td>...</td>\n","      <td>-0.042201</td>\n","      <td>0.017191</td>\n","      <td>0.01425</td>\n","      <td>0.59565</td>\n","      <td>-0.063107</td>\n","      <td>0.114934</td>\n","      <td>0.474869</td>\n","      <td>0.325373</td>\n","      <td>-0.002202</td>\n","      <td>0.008770</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 50 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f63f27a6-9b4b-4e0f-9cd3-a20b8b6c60e7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f63f27a6-9b4b-4e0f-9cd3-a20b8b6c60e7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f63f27a6-9b4b-4e0f-9cd3-a20b8b6c60e7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}],"source":["test.head()"]},{"cell_type":"markdown","metadata":{"id":"-WNf1aVmMiCd"},"source":["## 学習"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":567,"status":"ok","timestamp":1688098149353,"user":{"displayName":"田中大聖","userId":"10786730767244592948"},"user_tz":-540},"id":"jSjA7FmXbo8L"},"outputs":[],"source":["x_df_train, x_df_val, y_df_train, y_df_val = TTS(df_x, df_y, test_size=0.2, random_state=71)\n","lgb_train = lgb.Dataset(x_df_train, y_df_train)\n","lgb_val = lgb.Dataset(x_df_val, y_df_val)\n","\n","def objective(trial):\n","  # 調整したいハイパーパラメータについて範囲を指定\n","  params = {\n","    'boosting_type': 'gbdt',\n","    'objective': 'regression_l1',\n","    'metric': 'mae',\n","    'learning_rate': 0.1,\n","    'n_estimators': 100,\n","    'importance_type': 'gain',\n","    'lambda_l1': 0,\n","    'lambda_l2': 0,\n","    'random_seed': 71,\n","    \"reg_alpha\": 0.1,\n","    \"reg_lambda\": 0.1,\n","    \"max_depth\": 10,\n","    \"colsample_bytree\": 1.0,\n","    \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","    \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","  }\n","  num_round = 100\n","  evaluation_results = {}\n","\n","  model = lgb.train(params, lgb_train,\n","                    num_boost_round=num_round,\n","                    valid_sets=[lgb_train, lgb_val],\n","                    categorical_feature=list_and+List_Encode,\n","                    evals_result=evaluation_results,   # 学習の経過を保存\n","                    early_stopping_rounds=20,          # アーリーストッピング\n","                    verbose_eval=1)\n","\n","  va_pred = model.predict(x_df_val)\n","  score = MAE(np.array(y_df_val), va_pred, squared=False)\n","  return score"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mu1Esdwvbv95","executionInfo":{"status":"ok","timestamp":1688098731485,"user_tz":-540,"elapsed":582137,"user":{"displayName":"田中大聖","userId":"10786730767244592948"}},"outputId":"11f8ccd9-693d-48dc-cd65-0f6903fdbde4"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:09:09,040] A new study created in memory with name: no-name-10a4e979-2628-4e58-9038-62d8213045f4\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n","New categorical_feature is ['ID', '今後の利用目的', '地区名', '市区町村コード', '改装', '都市計画', '都道府県名']\n","  _log_warning('categorical_feature in Dataset is overridden.\\n'\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.349797 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n","  _log_warning('Overriding the parameters from Reference Dataset.')\n","/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n","  _log_warning(f'{cat_alias} in param dict is overridden.')\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:09:40,756] Trial 0 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.3384286948321845, 'min_child_weight': 6.8344456043713215}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.331449 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:10:08,987] Trial 1 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.20456291632361392, 'min_child_weight': 4.56868104553865}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.367991 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:10:37,322] Trial 2 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.20755937283160245, 'min_child_weight': 5.045993049653546}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.335181 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:11:10,339] Trial 3 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.3509462463162144, 'min_child_weight': 5.18149653356733}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.738978 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:11:37,419] Trial 4 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.34459989894798526, 'min_child_weight': 7.514106423445968}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.715708 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:12:04,687] Trial 5 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.26152909597025664, 'min_child_weight': 6.311384497149838}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.364811 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:12:32,088] Trial 6 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.1520355234433024, 'min_child_weight': 5.4820687840439755}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.356746 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:12:59,701] Trial 7 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.4741112582271104, 'min_child_weight': 4.853711834146186}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.338900 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:13:32,700] Trial 8 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.13922500694497444, 'min_child_weight': 4.858362987522907}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.363179 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:14:03,662] Trial 9 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.37094187407127943, 'min_child_weight': 7.859329451686523}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.342583 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:14:31,681] Trial 10 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.48673552197740944, 'min_child_weight': 2.7891090407831163}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.363661 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:14:59,809] Trial 11 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.2567582382939605, 'min_child_weight': 3.222804424741486}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.361587 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:15:28,103] Trial 12 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.10788839900304897, 'min_child_weight': 1.2829727024165485}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.354684 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:15:56,430] Trial 13 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.20327162234712154, 'min_child_weight': 6.492411315670919}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.360920 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:16:24,782] Trial 14 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.2922112738712439, 'min_child_weight': 3.909835675320152}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.369428 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:16:53,537] Trial 15 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.4149800265068453, 'min_child_weight': 6.757701790861184}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.782905 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:17:21,723] Trial 16 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.3097970530348156, 'min_child_weight': 5.8440748650175225}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.735711 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:17:49,512] Trial 17 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.21475697138331215, 'min_child_weight': 6.9559658975200795}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.257635 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:18:18,132] Trial 18 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.3996497668384116, 'min_child_weight': 6.039034037079253}. Best is trial 0 with value: 0.13966552898233564.\n","<ipython-input-15-7c4cc347af33>:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bylevel\": trial.suggest_uniform('colsample_bylevel', 0.1, 0.5),\n","<ipython-input-15-7c4cc347af33>:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"min_child_weight\": trial.suggest_uniform('min_child_weight', 1, 8),\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n","[LightGBM] [Warning] Unknown parameter: importance_type\n","[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.1 will be ignored. Current value: lambda_l2=0\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.782955 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 14764\n","[LightGBM] [Info] Number of data points in the train set: 612329, number of used features: 50\n","[LightGBM] [Info] Start training from score 7.278754\n","[1]\ttraining's l1: 0.252704\tvalid_1's l1: 0.252389\n","Training until validation scores don't improve for 20 rounds\n","[2]\ttraining's l1: 0.236936\tvalid_1's l1: 0.236686\n","[3]\ttraining's l1: 0.223087\tvalid_1's l1: 0.222861\n","[4]\ttraining's l1: 0.210603\tvalid_1's l1: 0.210427\n","[5]\ttraining's l1: 0.199092\tvalid_1's l1: 0.198949\n","[6]\ttraining's l1: 0.189766\tvalid_1's l1: 0.189672\n","[7]\ttraining's l1: 0.180513\tvalid_1's l1: 0.180468\n","[8]\ttraining's l1: 0.172553\tvalid_1's l1: 0.172502\n","[9]\ttraining's l1: 0.165699\tvalid_1's l1: 0.165686\n","[10]\ttraining's l1: 0.158992\tvalid_1's l1: 0.158999\n","[11]\ttraining's l1: 0.1534\tvalid_1's l1: 0.153409\n","[12]\ttraining's l1: 0.148418\tvalid_1's l1: 0.148446\n","[13]\ttraining's l1: 0.143667\tvalid_1's l1: 0.143704\n","[14]\ttraining's l1: 0.139273\tvalid_1's l1: 0.139355\n","[15]\ttraining's l1: 0.135575\tvalid_1's l1: 0.13567\n","[16]\ttraining's l1: 0.132189\tvalid_1's l1: 0.132326\n","[17]\ttraining's l1: 0.129021\tvalid_1's l1: 0.129194\n","[18]\ttraining's l1: 0.126289\tvalid_1's l1: 0.126504\n","[19]\ttraining's l1: 0.123658\tvalid_1's l1: 0.123904\n","[20]\ttraining's l1: 0.12122\tvalid_1's l1: 0.121507\n","[21]\ttraining's l1: 0.118974\tvalid_1's l1: 0.119298\n","[22]\ttraining's l1: 0.117045\tvalid_1's l1: 0.117386\n","[23]\ttraining's l1: 0.115205\tvalid_1's l1: 0.115587\n","[24]\ttraining's l1: 0.11333\tvalid_1's l1: 0.113727\n","[25]\ttraining's l1: 0.111584\tvalid_1's l1: 0.111991\n","[26]\ttraining's l1: 0.1102\tvalid_1's l1: 0.110633\n","[27]\ttraining's l1: 0.108672\tvalid_1's l1: 0.109139\n","[28]\ttraining's l1: 0.107292\tvalid_1's l1: 0.107801\n","[29]\ttraining's l1: 0.105808\tvalid_1's l1: 0.106354\n","[30]\ttraining's l1: 0.104675\tvalid_1's l1: 0.105253\n","[31]\ttraining's l1: 0.103448\tvalid_1's l1: 0.104076\n","[32]\ttraining's l1: 0.102524\tvalid_1's l1: 0.103192\n","[33]\ttraining's l1: 0.101491\tvalid_1's l1: 0.102194\n","[34]\ttraining's l1: 0.100523\tvalid_1's l1: 0.101264\n","[35]\ttraining's l1: 0.0996719\tvalid_1's l1: 0.100465\n","[36]\ttraining's l1: 0.0987221\tvalid_1's l1: 0.0995602\n","[37]\ttraining's l1: 0.0980159\tvalid_1's l1: 0.0988824\n","[38]\ttraining's l1: 0.0972847\tvalid_1's l1: 0.0981814\n","[39]\ttraining's l1: 0.0966355\tvalid_1's l1: 0.0975732\n","[40]\ttraining's l1: 0.0959962\tvalid_1's l1: 0.0969808\n","[41]\ttraining's l1: 0.0954237\tvalid_1's l1: 0.0964385\n","[42]\ttraining's l1: 0.0948614\tvalid_1's l1: 0.0959017\n","[43]\ttraining's l1: 0.0942942\tvalid_1's l1: 0.0953663\n","[44]\ttraining's l1: 0.093774\tvalid_1's l1: 0.0948839\n","[45]\ttraining's l1: 0.0933045\tvalid_1's l1: 0.0944419\n","[46]\ttraining's l1: 0.0927635\tvalid_1's l1: 0.0939119\n","[47]\ttraining's l1: 0.0923045\tvalid_1's l1: 0.0934924\n","[48]\ttraining's l1: 0.091852\tvalid_1's l1: 0.0930669\n","[49]\ttraining's l1: 0.0914174\tvalid_1's l1: 0.0926653\n","[50]\ttraining's l1: 0.0910338\tvalid_1's l1: 0.0922978\n","[51]\ttraining's l1: 0.0905629\tvalid_1's l1: 0.0918686\n","[52]\ttraining's l1: 0.0901454\tvalid_1's l1: 0.0914933\n","[53]\ttraining's l1: 0.0898159\tvalid_1's l1: 0.0911971\n","[54]\ttraining's l1: 0.089478\tvalid_1's l1: 0.0909028\n","[55]\ttraining's l1: 0.089077\tvalid_1's l1: 0.0905222\n","[56]\ttraining's l1: 0.0887481\tvalid_1's l1: 0.0902072\n","[57]\ttraining's l1: 0.0884514\tvalid_1's l1: 0.0899422\n","[58]\ttraining's l1: 0.0881431\tvalid_1's l1: 0.0896721\n","[59]\ttraining's l1: 0.0878127\tvalid_1's l1: 0.089378\n","[60]\ttraining's l1: 0.0875029\tvalid_1's l1: 0.0890884\n","[61]\ttraining's l1: 0.0872318\tvalid_1's l1: 0.0888494\n","[62]\ttraining's l1: 0.0869751\tvalid_1's l1: 0.0886298\n","[63]\ttraining's l1: 0.0867096\tvalid_1's l1: 0.0883802\n","[64]\ttraining's l1: 0.0864619\tvalid_1's l1: 0.088165\n","[65]\ttraining's l1: 0.0862274\tvalid_1's l1: 0.0879567\n","[66]\ttraining's l1: 0.0859906\tvalid_1's l1: 0.0877469\n","[67]\ttraining's l1: 0.0857344\tvalid_1's l1: 0.087514\n","[68]\ttraining's l1: 0.085491\tvalid_1's l1: 0.0873049\n","[69]\ttraining's l1: 0.0852727\tvalid_1's l1: 0.0871096\n","[70]\ttraining's l1: 0.0850778\tvalid_1's l1: 0.0869463\n","[71]\ttraining's l1: 0.0847923\tvalid_1's l1: 0.0866866\n","[72]\ttraining's l1: 0.0846075\tvalid_1's l1: 0.0865248\n","[73]\ttraining's l1: 0.0844188\tvalid_1's l1: 0.0863699\n","[74]\ttraining's l1: 0.0842159\tvalid_1's l1: 0.0861974\n","[75]\ttraining's l1: 0.0840363\tvalid_1's l1: 0.0860468\n","[76]\ttraining's l1: 0.0838743\tvalid_1's l1: 0.085896\n","[77]\ttraining's l1: 0.0836539\tvalid_1's l1: 0.0857064\n","[78]\ttraining's l1: 0.0834577\tvalid_1's l1: 0.0855304\n","[79]\ttraining's l1: 0.0832699\tvalid_1's l1: 0.0853697\n","[80]\ttraining's l1: 0.083078\tvalid_1's l1: 0.0852143\n","[81]\ttraining's l1: 0.0829124\tvalid_1's l1: 0.0850636\n","[82]\ttraining's l1: 0.082774\tvalid_1's l1: 0.0849501\n","[83]\ttraining's l1: 0.0825896\tvalid_1's l1: 0.0847909\n","[84]\ttraining's l1: 0.0824317\tvalid_1's l1: 0.0846646\n","[85]\ttraining's l1: 0.0822897\tvalid_1's l1: 0.0845611\n","[86]\ttraining's l1: 0.0821482\tvalid_1's l1: 0.0844468\n","[87]\ttraining's l1: 0.0819851\tvalid_1's l1: 0.0843083\n","[88]\ttraining's l1: 0.0818496\tvalid_1's l1: 0.0842006\n","[89]\ttraining's l1: 0.0817096\tvalid_1's l1: 0.0840808\n","[90]\ttraining's l1: 0.0815777\tvalid_1's l1: 0.0839749\n","[91]\ttraining's l1: 0.0814506\tvalid_1's l1: 0.0838761\n","[92]\ttraining's l1: 0.0813061\tvalid_1's l1: 0.0837528\n","[93]\ttraining's l1: 0.0811325\tvalid_1's l1: 0.0836035\n","[94]\ttraining's l1: 0.0810429\tvalid_1's l1: 0.0835373\n","[95]\ttraining's l1: 0.0809437\tvalid_1's l1: 0.0834604\n","[96]\ttraining's l1: 0.0808019\tvalid_1's l1: 0.083341\n","[97]\ttraining's l1: 0.0806603\tvalid_1's l1: 0.0832192\n","[98]\ttraining's l1: 0.0805049\tvalid_1's l1: 0.0830861\n","[99]\ttraining's l1: 0.0804199\tvalid_1's l1: 0.0830185\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n","Did not meet early stopping. Best iteration is:\n","[100]\ttraining's l1: 0.080321\tvalid_1's l1: 0.0829397\n"]},{"output_type":"stream","name":"stderr","text":["[I 2023-06-30 04:18:50,986] Trial 19 finished with value: 0.13966552898233564 and parameters: {'colsample_bylevel': 0.29134943603284275, 'min_child_weight': 4.103256631128403}. Best is trial 0 with value: 0.13966552898233564.\n"]}],"source":["study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=20)"]},{"cell_type":"code","source":["print('Number of finished trials:', len(study.trials))\n","print('Best trial:', study.best_trial.params)"],"metadata":{"id":"wZtd8NXdjVBD","executionInfo":{"status":"ok","timestamp":1688098731486,"user_tz":-540,"elapsed":50,"user":{"displayName":"田中大聖","userId":"10786730767244592948"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a3f59d06-f694-4afb-9288-90d7747b2e0d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of finished trials: 20\n","Best trial: {'colsample_bylevel': 0.3384286948321845, 'min_child_weight': 6.8344456043713215}\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1SmuzGLCyctVnsce6oxJIVZ0o7-ZmFJxE","timestamp":1686805122715},{"file_id":"1RErRk4_p5uApUgAwlc-tf8ZzUT_KYfgA","timestamp":1686024637972},{"file_id":"1rkbP-m3dSGsBsoejCkl38i9h4fEEHPDx","timestamp":1685346477183}],"authorship_tag":"ABX9TyOQTpHBu107JRpkLhP8Teob"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}